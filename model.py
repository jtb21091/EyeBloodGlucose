import os
import cv2
import pandas as pd  # type: ignore
import numpy as np
import logging
import mediapipe as mp  # type: ignore
import time
from datetime import datetime
from contextlib import contextmanager
from typing import Optional

# Setup logging: change level to DEBUG to see detailed logs.
logging.basicConfig(level=logging.DEBUG, format="%(asctime)s - %(levelname)s - %(message)s")

# Define file paths and constants
LABELS_FILE = os.environ.get("EBG_LABELS_FILE", "eye_glucose_data/labels.csv")
IMAGE_DIR = "eye_glucose_data/images"
os.makedirs(IMAGE_DIR, exist_ok=True)
os.makedirs(os.path.dirname(LABELS_FILE), exist_ok=True)

CSV_COLUMNS = [
    'filename',
    'session_id',
    'blood_glucose',
    'pupil_size',
    'sclera_redness',
    'vein_prominence',
    'capture_duration',
    'ir_intensity',
    'scleral_vein_density',
    'ir_temperature',
    'tear_film_reflectivity',
    'sclera_color_balance',
    'vein_pulsation_intensity',
    'birefringence_index',
    'lens_clarity_score',
    'sclera_yellowness',
    'vessel_tortuosity',
    'image_quality_score'
]

# Edge detection thresholds (tuned further)
EDGE_LOW_THRESHOLD = 10
EDGE_HIGH_THRESHOLD = 50

# Camera settings
CAMERA_WIDTH = 1920
CAMERA_HEIGHT = 1080
WARMUP_FRAMES = 30  # Increased for better auto-adjustment

# Initialize Mediapipe Face Mesh
mp_face_mesh = mp.solutions.face_mesh


def adjust_camera_settings(cap):
    """Optimize camera settings for better image quality."""
    try:
        # Try to set auto exposure (may not work on all cameras)
        cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)  # Manual mode
        cap.set(cv2.CAP_PROP_EXPOSURE, -5)  # Adjust exposure
    except:
        logging.debug("Could not set exposure settings")
    
    try:
        # Increase brightness
        cap.set(cv2.CAP_PROP_BRIGHTNESS, 0.6)
    except:
        logging.debug("Could not set brightness")
    
    try:
        # Adjust contrast
        cap.set(cv2.CAP_PROP_CONTRAST, 0.5)
    except:
        logging.debug("Could not set contrast")
    
    try:
        # Increase saturation (helps with color features)
        cap.set(cv2.CAP_PROP_SATURATION, 0.6)
    except:
        logging.debug("Could not set saturation")
    
    try:
        # Enable autofocus if supported
        cap.set(cv2.CAP_PROP_AUTOFOCUS, 1)
    except:
        logging.debug("Could not set autofocus")
    
    logging.debug("Camera settings optimization attempted")


def ensure_labels_file_structure():
    """Ensure the labels CSV contains the expected columns (including session id)."""
    if not os.path.exists(LABELS_FILE):
        return

    try:
        df = pd.read_csv(LABELS_FILE)
    except pd.errors.EmptyDataError:
        return

    changed = False

    if 'session_id' not in df.columns:
        df.insert(1, 'session_id', '')
        changed = True

    for col in CSV_COLUMNS:
        if col not in df.columns:
            df[col] = np.nan
            changed = True

    if list(df.columns) != CSV_COLUMNS:
        df = df[[col for col in CSV_COLUMNS if col in df.columns]]
        changed = True

    if changed:
        df.to_csv(LABELS_FILE, index=False, float_format='%.10f')


@contextmanager
def open_camera(width=CAMERA_WIDTH, height=CAMERA_HEIGHT):
    """Context manager for safe camera access with optimized settings."""
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        raise RuntimeError("Could not open webcam")
    
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
    
    # Apply camera optimizations
    adjust_camera_settings(cap)
    
    logging.debug("Camera resolution set to: %.0f x %.0f",
                  cap.get(cv2.CAP_PROP_FRAME_WIDTH), 
                  cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    try:
        yield cap
    finally:
        cap.release()
        logging.debug("Camera released")


def enhance_roi(roi):
    """Apply image enhancements to improve quality."""
    if roi is None or roi.size == 0:
        return roi
    
    try:
        # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
        lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))
        l = clahe.apply(l)
        
        enhanced = cv2.merge([l, a, b])
        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        
        # Sharpen the image slightly
        kernel = np.array([[-0.5,-0.5,-0.5],
                           [-0.5, 5,-0.5],
                           [-0.5,-0.5,-0.5]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)
        
        # Denoise while preserving details
        denoised = cv2.fastNlMeansDenoisingColored(sharpened, None, 6, 6, 7, 21)
        
        logging.debug("ROI enhancement applied successfully")
        return denoised
    except Exception as e:
        logging.warning(f"Error enhancing ROI: {e}. Using original.")
        return roi


def is_blurry(image, threshold=100.0):
    """Check if the image is blurry using the variance of the Laplacian."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    variance = cv2.Laplacian(gray, cv2.CV_64F).var()
    return variance < threshold, variance


def get_pupil_size(image):
    """
    Detect and measure pupil size using adaptive thresholding and contour detection.
    Histogram equalization is applied to improve contrast.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray_eq = cv2.equalizeHist(gray)
    adaptive_thresh = cv2.adaptiveThreshold(
        gray_eq, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV, 11, 2)
    
    contours, _ = cv2.findContours(adaptive_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return None
    largest_contour = max(contours, key=cv2.contourArea)
    (_, _), radius = cv2.minEnclosingCircle(largest_contour)
    return round(radius * 2, 10)


def get_sclera_redness(image):
    """
    Analyze sclera redness using the HSV color space.
    Combines two ranges of red hues in HSV.
    """
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    lower_red1 = np.array([0, 50, 50])
    upper_red1 = np.array([10, 255, 255])
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    lower_red2 = np.array([170, 50, 50])
    upper_red2 = np.array([180, 255, 255])
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask = mask1 | mask2
    redness_score = np.mean(mask)
    return round(redness_score, 10)


def get_vein_prominence(image):
    """Estimate vein prominence using edge detection and contrast enhancement."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, EDGE_LOW_THRESHOLD, EDGE_HIGH_THRESHOLD)
    mean_edges = np.mean(edges)
    logging.debug("get_vein_prominence: Mean edge intensity = %.10f", mean_edges)
    return round(mean_edges, 10)


def get_ir_intensity(image):
    """Calculate IR intensity from the grayscale average."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    return round(np.mean(gray), 10)


def get_scleral_vein_density(image):
    """Estimate scleral vein density using edge detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, EDGE_LOW_THRESHOLD, EDGE_HIGH_THRESHOLD)
    sum_edges = np.sum(edges)
    density = sum_edges / edges.size
    logging.debug("get_scleral_vein_density: Sum of edges = %.10f, Density = %.10f", sum_edges, density)
    return round(density, 10)


def get_tear_film_reflectivity(image):
    """Estimate tear film reflectivity based on brightness variance."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    return round(np.var(gray), 10)


def get_sclera_color_balance(image):
    """Analyze sclera color balance using the RGB ratio."""
    mean_color = np.mean(image, axis=(0, 1))
    return round(mean_color[2] / (mean_color[0] + 1e-5), 10)


def get_vein_pulsation_intensity(image):
    """Estimate vein pulsation intensity using frequency analysis."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    return round(np.std(gray), 10)


def get_birefringence_index(image):
    """
    Calculate the birefringence index.
    This placeholder algorithm calculates the ratio of standard deviation to mean intensity.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    mean_intensity = np.mean(gray)
    if mean_intensity == 0:
        return 0.0
    std_intensity = np.std(gray)
    birefringence = std_intensity / mean_intensity
    return round(birefringence, 10)


def get_ir_temperature(image):
    """
    Estimate the IR temperature.
    This placeholder algorithm maps the average grayscale intensity to a temperature value.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    mean_intensity = np.mean(gray)
    temperature = (mean_intensity / 255.0) * 40 + 20
    return round(temperature, 10)


def get_lens_clarity_score(image):
    """
    Measure lens opacity/clarity score.
    Higher values indicate more clarity/less opacity.
    Diabetes can cause lens changes over time.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    # Focus on central region (approximate lens area)
    center_y_start, center_y_end = h // 3, 2 * h // 3
    center_x_start, center_x_end = w // 3, 2 * w // 3
    center = gray[center_y_start:center_y_end, center_x_start:center_x_end]
    
    if center.size == 0:
        return 0.0
    
    clarity = np.std(center) / (np.mean(center) + 1e-5)
    return round(clarity, 10)


def get_sclera_yellowness(image):
    """
    Measure yellowish tint in sclera using LAB color space.
    Can indicate metabolic changes or jaundice.
    The b channel in LAB represents yellow-blue axis.
    """
    try:
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        b_channel = lab[:, :, 2]  # Yellow-blue axis (higher = more yellow)
        yellowness = np.mean(b_channel)
        return round(yellowness, 10)
    except Exception as e:
        logging.warning("Error calculating sclera yellowness: %s", e)
        return 0.0


def get_vessel_tortuosity(image):
    """
    Estimate blood vessel tortuosity (twistedness) using edge curvature analysis.
    High glucose levels can increase vessel tortuosity.
    Uses edge detection and analyzes local curvature.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Apply bilateral filter to reduce noise while preserving edges
    filtered = cv2.bilateralFilter(gray, 9, 75, 75)
    
    # Detect edges with stricter thresholds for vessel detection
    edges = cv2.Canny(filtered, 30, 90)
    
    # Find contours representing vessels
    contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
    
    if not contours:
        return 0.0
    
    # Calculate tortuosity for each contour
    tortuosity_scores = []
    for contour in contours:
        if len(contour) > 10:  # Need sufficient points
            # Calculate arc length
            arc_length = cv2.arcLength(contour, False)
            
            # Calculate chord length (straight line distance)
            if len(contour) >= 2:
                start_point = contour[0][0]
                end_point = contour[-1][0]
                chord_length = np.linalg.norm(start_point - end_point)
                
                # Tortuosity = arc_length / chord_length
                # (1.0 = perfectly straight, higher = more tortuous)
                if chord_length > 0:
                    tortuosity = arc_length / (chord_length + 1e-5)
                    tortuosity_scores.append(tortuosity)
    
    if tortuosity_scores:
        # Return mean tortuosity across all detected vessels
        mean_tortuosity = np.mean(tortuosity_scores)
        return round(mean_tortuosity, 10)
    else:
        return 0.0


def get_image_quality_score(image):
    """
    Calculate composite image quality metric.
    Combines blur, brightness, and contrast into a single score.
    Higher scores indicate better quality images.
    """
    _, blur_var = is_blurry(image)
    brightness = np.mean(image)
    contrast = np.std(image)
    
    # Normalize each component (with reasonable expected ranges)
    blur_score = min(blur_var / 100.0, 1.0)  # 100+ is good
    brightness_score = 1.0 - abs(brightness - 128) / 128.0  # 128 is ideal
    contrast_score = min(contrast / 50.0, 1.0)  # 50+ is good
    
    # Composite quality (0-1 scale, then scaled to 0-100)
    quality = (blur_score + brightness_score + contrast_score) / 3.0 * 100
    
    logging.debug("Image quality - Blur: %.2f, Brightness: %.2f, Contrast: %.2f, Overall: %.2f", 
                  blur_score * 100, brightness_score * 100, contrast_score * 100, quality)
    
    return round(quality, 10)


def measure_capture_duration(cap):
    """
    Measure the time duration to capture 10 frames.
    Renamed from pupil_response_time for accuracy.
    """
    pupil_sizes = []
    start_time = time.time()
    
    for _ in range(10):
        ret, frame = cap.read()
        if not ret:
            continue
        pupil_size = get_pupil_size(frame)
        if pupil_size is not None:
            pupil_sizes.append(pupil_size)
        time.sleep(0.1)
    
    if len(pupil_sizes) < 2:
        return None
    
    duration = round(time.time() - start_time, 10)
    return duration


def extract_eye_roi(frame):
    """
    Extract the eye region (ROI) from a frame using Mediapipe Face Mesh.
    Returns the ROI and logs any quality warnings.
    IMPROVED: Larger padding for better context.
    """
    if np.mean(frame) < 10:
        logging.warning("Captured frame is very dark. Check your lighting conditions.")

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    with mp_face_mesh.FaceMesh(static_image_mode=True,
                               max_num_faces=1,
                               refine_landmarks=True,
                               min_detection_confidence=0.5) as face_mesh:
        results = face_mesh.process(rgb_frame)
        
        if not results.multi_face_landmarks:
            logging.error("No face landmarks detected. Using full frame as ROI.")
            return frame
        
        face_landmarks = results.multi_face_landmarks[0]
        ih, iw, _ = frame.shape
        left_eye_indices = {idx for connection in mp_face_mesh.FACEMESH_LEFT_EYE for idx in connection}
        
        x_coords = []
        y_coords = []
        for idx in left_eye_indices:
            lm = face_landmarks.landmark[idx]
            x_coords.append(int(lm.x * iw))
            y_coords.append(int(lm.y * ih))
        
        if x_coords and y_coords:
            # IMPROVED: Adaptive padding based on eye size
            # Calculate eye dimensions
            eye_width = max(x_coords) - min(x_coords)
            eye_height = max(y_coords) - min(y_coords)
            
            # Use 40% of eye size as padding (balances context vs purity)
            # Minimum 15 pixels, maximum 25 pixels
            pad_x = int(np.clip(eye_width * 0.4, 15, 25))
            pad_y = int(np.clip(eye_height * 0.4, 15, 25))
            
            x_min = max(min(x_coords) - pad_x, 0)
            x_max = min(max(x_coords) + pad_x, iw)
            y_min = max(min(y_coords) - pad_y, 0)
            y_max = min(max(y_coords) + pad_y, ih)
            
            logging.debug(f"Eye ROI padding: X={pad_x}px, Y={pad_y}px (adaptive)")
            roi = frame[y_min:y_max, x_min:x_max]
            
            if roi.size == 0:
                logging.error("ROI extraction resulted in an empty image. Using full frame as ROI.")
                return frame
            
            if np.mean(roi) < 10:
                logging.warning("The ROI appears very dark. Check your lighting conditions.")
            
            blurry_roi, variance_roi = is_blurry(roi)
            if blurry_roi:
                logging.warning("The extracted ROI appears blurry (Laplacian variance: %.10f).", variance_roi)
            
            return roi
        else:
            logging.error("No eye landmarks found. Using full frame as ROI.")
            return frame


def show_preview_and_capture(cap, duration=5):
    """Show preview window so user can position themselves before capture."""
    print(f"\nüì∏ POSITION YOURSELF - Capturing in {duration} seconds...")
    print("   ‚úì Remove glasses")
    print("   ‚úì Look directly at camera")
    print("   ‚úì Ensure good lighting (face a window)")
    print("   ‚úì Distance: 12-18 inches from camera")
    print("   ‚úì Press 'q' to cancel\n")
    
    start_time = time.time()
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Calculate countdown
        elapsed = time.time() - start_time
        remaining = max(0, duration - elapsed)
        
        # Draw countdown and instructions on frame
        display = frame.copy()
        h, w = display.shape[:2]
        
        # Large countdown
        countdown_text = f"{remaining:.1f}s"
        cv2.putText(display, countdown_text, 
                   (w//2 - 80, h//2), cv2.FONT_HERSHEY_SIMPLEX, 3.0, (0, 255, 0), 5)
        
        # Instructions
        cv2.putText(display, "REMOVE GLASSES!", 
                   (50, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
        cv2.putText(display, "Look at camera", 
                   (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
        cv2.putText(display, "Press 'q' to cancel", 
                   (50, h - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        cv2.imshow("Eye Capture Preview", display)
        
        # Check for quit or timeout
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            cv2.destroyAllWindows()
            return None
        
        if elapsed >= duration:
            cv2.destroyAllWindows()
            return frame
    
    cv2.destroyAllWindows()
    return None


def capture_and_measure():
    """
    Capture eye images and perform all measurements in a single camera session.
    Returns filename, roi, and all measurements.
    IMPROVED: Enhanced image quality processing with preview window.
    """
    try:
        with open_camera() as cap:
            # Quick warmup
            logging.info("Warming up camera...")
            for i in range(10):
                ret, _ = cap.read()
                if not ret:
                    continue
                time.sleep(0.1)
            
            # Show preview and capture
            frame = show_preview_and_capture(cap, duration=5)
            
            if frame is None:
                logging.error("Capture cancelled or failed.")
                return None
            
            # Check frame quality
            blurry, variance = is_blurry(frame)
            if blurry:
                logging.warning("Captured image appears blurry (Laplacian variance: %.10f).", variance)
            
            # Extract eye ROI
            roi = extract_eye_roi(frame)
            
            # IMPROVED: Enhance the ROI before processing
            roi_enhanced = enhance_roi(roi)
            
            # Measure capture duration (needs camera still open)
            logging.info("Measuring capture duration...")
            capture_duration = measure_capture_duration(cap)
            
            # Save the enhanced ROI with maximum quality
            file_name = f"eye_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            file_path = os.path.join(IMAGE_DIR, file_name)
            # IMPROVED: Save with no compression for maximum quality
            cv2.imwrite(file_path, roi_enhanced, [cv2.IMWRITE_PNG_COMPRESSION, 0])
            logging.info("Captured enhanced eye ROI image: %s", file_name)
            
            # Compute all measurements from the enhanced ROI
            measurements = {
                'pupil_size': get_pupil_size(roi_enhanced),
                'sclera_redness': get_sclera_redness(roi_enhanced),
                'vein_prominence': get_vein_prominence(roi_enhanced),
                'capture_duration': capture_duration,
                'ir_intensity': get_ir_intensity(roi_enhanced),
                'scleral_vein_density': get_scleral_vein_density(roi_enhanced),
                'ir_temperature': get_ir_temperature(roi_enhanced),
                'tear_film_reflectivity': get_tear_film_reflectivity(roi_enhanced),
                'sclera_color_balance': get_sclera_color_balance(roi_enhanced),
                'vein_pulsation_intensity': get_vein_pulsation_intensity(roi_enhanced),
                'birefringence_index': get_birefringence_index(roi_enhanced),
                'lens_clarity_score': get_lens_clarity_score(roi_enhanced),
                'sclera_yellowness': get_sclera_yellowness(roi_enhanced),
                'vessel_tortuosity': get_vessel_tortuosity(roi_enhanced),
                'image_quality_score': get_image_quality_score(roi_enhanced)
            }
            
            return file_name, measurements
    
    except RuntimeError as e:
        logging.error("Camera error: %s", e)
        return None
    except Exception as e:
        logging.error("Unexpected error during capture: %s", e)
        return None


def test_focus():
    """Test different focus positions to find optimal setting."""
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
    
    print("\nüéØ FOCUS TEST MODE")
    print("=" * 60)
    print("Instructions:")
    print("  ‚Ä¢ Adjust your distance from camera")
    print("  ‚Ä¢ Try different lighting")
    print("  ‚Ä¢ Wait for GREEN (blur score >100)")
    print("  ‚Ä¢ Press 's' to save a good frame")
    print("  ‚Ä¢ Press 'q' to quit")
    print("=" * 60 + "\n")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Calculate blur score
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # Show frame with blur score
        display = frame.copy()
        color = (0, 255, 0) if blur_score > 100 else (0, 0, 255)
        status = "GOOD - Press 's' to save" if blur_score > 100 else "TOO BLURRY - Adjust position/lighting"
        
        cv2.putText(display, f"Blur Score: {blur_score:.1f}", 
                   (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)
        cv2.putText(display, status, 
                   (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        cv2.putText(display, "Target: >100 for good quality", 
                   (50, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(display, "Press 'q' to quit, 's' to save", 
                   (50, display.shape[0] - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.imshow("Focus Test", display)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('s'):
            cv2.imwrite("focus_test.png", frame)
            print(f"\n‚úì Saved focus_test.png! Blur score: {blur_score:.1f}")
            if blur_score > 100:
                print("‚úì Good quality! This distance/lighting should work well.")
            else:
                print("‚ö† Still blurry. Try adjusting position or lighting.")
    
    cap.release()
    cv2.destroyAllWindows()
    print("\nFocus test complete!")


def update_data():
    """Capture an eye image, compute measurement values, and update the dataset."""
    ensure_labels_file_structure()
    result = capture_and_measure()
    
    if result is None:
        logging.error("No data captured. Skipping update.")
        return
    
    filename, measurements = result
    session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    new_entry = pd.DataFrame([[
        filename, session_id, "",
        measurements['pupil_size'],
        measurements['sclera_redness'],
        measurements['vein_prominence'],
        measurements['capture_duration'],
        measurements['ir_intensity'],
        measurements['scleral_vein_density'],
        measurements['ir_temperature'],
        measurements['tear_film_reflectivity'],
        measurements['sclera_color_balance'],
        measurements['vein_pulsation_intensity'],
        measurements['birefringence_index'],
        measurements['lens_clarity_score'],
        measurements['sclera_yellowness'],
        measurements['vessel_tortuosity'],
        measurements['image_quality_score']
    ]], columns=CSV_COLUMNS)

    # Use append mode so that each run adds a new row
    if not os.path.exists(LABELS_FILE):
        new_entry.to_csv(LABELS_FILE, index=False, float_format='%.10f')
        logging.info("CSV created and new data added: %s", filename)
    else:
        new_entry.to_csv(LABELS_FILE, mode='a', header=False, index=False, float_format='%.10f')
        logging.info("Appended new data to CSV: %s", filename)
    
    print(f"\n‚úì Capture complete! Image saved as: {filename}")
    print(f"‚úì Image quality score: {measurements['image_quality_score']:.1f}/100")
    print("\nüí° Tip: For best results, ensure good lighting and look directly at the camera")
    print("\nRemember to add your blood glucose reading to the CSV file.")


def batch_capture_session(num_photos=10, interval_seconds=3, session_id: Optional[str] = None):
    """
    Capture multiple eye photos in a batch session for dataset building.
    Automatically captures photos at intervals with quality checks.
    """
    ensure_labels_file_structure()
    session_id = session_id or f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    print(f"\nüéØ BATCH CAPTURE SESSION")
    print("=" * 60)
    print(f"üì∏ Will capture {num_photos} photos every {interval_seconds} seconds")
    print(f"üÜî Session ID: {session_id}")
    print("‚úì Remove glasses and maintain good lighting")
    print("‚úì Look directly at camera for each capture")
    print("‚úì Press 'q' anytime to stop early")
    print("=" * 60 + "\n")
    
    captured_files = []
    quality_scores = []
    
    try:
        with open_camera() as cap:
            # Quick warmup
            logging.info("Warming up camera...")
            for i in range(10):
                ret, _ = cap.read()
                if not ret:
                    continue
                time.sleep(0.1)
            
            for photo_num in range(1, num_photos + 1):
                print(f"\nüì∏ Preparing capture {photo_num}/{num_photos}...")
                
                # Show countdown
                countdown_start = time.time()
                while time.time() - countdown_start < interval_seconds:
                    ret, frame = cap.read()
                    if not ret:
                        continue
                    
                    remaining = interval_seconds - (time.time() - countdown_start)
                    
                    # Check quality in real-time
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
                    
                    # Draw countdown and quality info
                    display = frame.copy()
                    h, w = display.shape[:2]
                    
                    # Countdown
                    countdown_text = f"Capture in: {remaining:.1f}s"
                    cv2.putText(display, countdown_text, 
                               (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 3)
                    
                    # Photo counter
                    counter_text = f"Photo {photo_num}/{num_photos}"
                    cv2.putText(display, counter_text, 
                               (50, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
                    
                    # Quality check
                    quality_color = (0, 255, 0) if blur_score > 100 else (0, 165, 255)
                    quality_text = f"Quality: {blur_score:.0f} ({'Good' if blur_score > 100 else 'Fair'})"
                    cv2.putText(display, quality_text, 
                               (50, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.8, quality_color, 2)
                    
                    # Instructions
                    cv2.putText(display, "Look directly at camera", 
                               (50, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    cv2.putText(display, "Press 'q' to stop", 
                               (50, h - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
                    
                    cv2.imshow("Batch Capture Session", display)
                    
                    # Check for quit
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        cv2.destroyAllWindows()
                        print(f"\n‚èπÔ∏è Session stopped early. Captured {len(captured_files)} photos.")
                        return captured_files, quality_scores, session_id
                
                # Capture the photo
                ret, frame = cap.read()
                if not ret:
                    print(f"‚ùå Failed to capture photo {photo_num}")
                    continue
                
                # Extract ROI and enhance
                roi = extract_eye_roi(frame)
                roi_enhanced = enhance_roi(roi)
                
                # Check quality
                quality_score = get_image_quality_score(roi_enhanced)
                quality_scores.append(quality_score)
                
                # Measure capture duration (simplified for batch mode)
                batch_capture_duration = interval_seconds
                
                # Save the enhanced ROI
                file_name = f"eye_batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{photo_num:02d}.png"
                file_path = os.path.join(IMAGE_DIR, file_name)
                cv2.imwrite(file_path, roi_enhanced, [cv2.IMWRITE_PNG_COMPRESSION, 0])
                
                captured_files.append(file_name)
                
                # Compute all measurements
                measurements = {
                    'pupil_size': get_pupil_size(roi_enhanced),
                    'sclera_redness': get_sclera_redness(roi_enhanced),
                    'vein_prominence': get_vein_prominence(roi_enhanced),
                    'capture_duration': batch_capture_duration,
                    'ir_intensity': get_ir_intensity(roi_enhanced),
                    'scleral_vein_density': get_scleral_vein_density(roi_enhanced),
                    'ir_temperature': get_ir_temperature(roi_enhanced),
                    'tear_film_reflectivity': get_tear_film_reflectivity(roi_enhanced),
                    'sclera_color_balance': get_sclera_color_balance(roi_enhanced),
                    'vein_pulsation_intensity': get_vein_pulsation_intensity(roi_enhanced),
                    'birefringence_index': get_birefringence_index(roi_enhanced),
                    'lens_clarity_score': get_lens_clarity_score(roi_enhanced),
                    'sclera_yellowness': get_sclera_yellowness(roi_enhanced),
                    'vessel_tortuosity': get_vessel_tortuosity(roi_enhanced),
                    'image_quality_score': quality_score
                }
                
                # Add to CSV with empty blood glucose (to be filled later)
                new_entry = pd.DataFrame([[
                    file_name, session_id, "",  # Empty blood glucose - user will fill this
                    measurements['pupil_size'],
                    measurements['sclera_redness'],
                    measurements['vein_prominence'],
                    measurements['capture_duration'],
                    measurements['ir_intensity'],
                    measurements['scleral_vein_density'],
                    measurements['ir_temperature'],
                    measurements['tear_film_reflectivity'],
                    measurements['sclera_color_balance'],
                    measurements['vein_pulsation_intensity'],
                    measurements['birefringence_index'],
                    measurements['lens_clarity_score'],
                    measurements['sclera_yellowness'],
                    measurements['vessel_tortuosity'],
                    measurements['image_quality_score']
                ]], columns=CSV_COLUMNS)
                
                # Append to CSV
                if not os.path.exists(LABELS_FILE):
                    new_entry.to_csv(LABELS_FILE, index=False, float_format='%.10f')
                else:
                    new_entry.to_csv(LABELS_FILE, mode='a', header=False, index=False, float_format='%.10f')
                
                print(f"‚úÖ Captured {file_name} (Quality: {quality_score:.1f}/100)")
                
            cv2.destroyAllWindows()
            
    except Exception as e:
        cv2.destroyAllWindows()
        logging.error(f"Error during batch capture: {e}")
        
    # Summary
    print(f"\nüéâ BATCH CAPTURE COMPLETE!")
    print("=" * 60)
    print(f"üì∏ Total photos captured: {len(captured_files)}")
    print(f"üÜî Session ID: {session_id}")
    print(f"üìä Average quality score: {np.mean(quality_scores):.1f}/100" if quality_scores else "N/A")
    print(f"üíæ Images saved to: {IMAGE_DIR}/")
    print(f"üìã Data added to: {LABELS_FILE}")
    print("\nüìù NEXT STEPS:")
    print("1. Check your blood glucose with glucometer")
    print("2. Edit the CSV file to add blood glucose values")
    print("3. Run training.py to retrain with new data")
    print("=" * 60)
    
    return captured_files, quality_scores, session_id


def process_batch(images):
    """
    Process a batch of images and extract features for each image.
    Args:
        images (list of np.ndarray): List of images to process.
    Returns:
        list of dict: List of feature dictionaries for each image.
    """
    batch_features = []

    for image in images:
        features = {
            'pupil_size': get_pupil_size(image),
            'sclera_redness': get_sclera_redness(image),
            'vein_prominence': get_vein_prominence(image),
            'ir_intensity': get_ir_intensity(image),
            'scleral_vein_density': get_scleral_vein_density(image),
            'tear_film_reflectivity': get_tear_film_reflectivity(image),
            # Add other feature extraction functions as needed
        }
        batch_features.append(features)

    logging.debug("Processed batch of %d images", len(images))
    return batch_features


if __name__ == "__main__":
    import sys
    # Optional override for output CSV path via CLI: --csv-out <path>
    # Example: python model.py --csv-out eye_glucose_data/labels.csv
    if "--csv-out" in sys.argv:
        try:
            idx = sys.argv.index("--csv-out")
            out_path = sys.argv[idx+1]
            globals()["LABELS_FILE"] = out_path
            os.makedirs(os.path.dirname(LABELS_FILE), exist_ok=True)
        except Exception:
            print("--csv-out requires a path argument")
            sys.exit(2)

    if len(sys.argv) > 1:
        if sys.argv[1] == "--test-focus":
            test_focus()
        elif sys.argv[1] == "--batch":
            # Parse optional parameters
            # Usage example with override:
            #   python model.py --batch 15 2 --csv-out eye_glucose_data/labels.csv
            # Consume potential numeric args only; flags handled above
            args = [a for a in sys.argv[2:] if not a.startswith("--csv-out")] 
            num_photos = int(args[0]) if len(args) > 0 and args[0].isdigit() else 10
            interval = int(args[1]) if len(args) > 1 and args[1].isdigit() else 3
            batch_capture_session(num_photos, interval)
        else:
            print("Usage:")
            print("  python model.py                                # Single capture")
            print("  python model.py --test-focus                   # Focus test mode")
            print("  python model.py --batch [N] [I]                # Batch capture N photos every I seconds")
            print("  python model.py --batch 15 2                   # Example: 15 photos every 2 seconds")
            print("  python model.py --csv-out path/to/labels.csv   # Override output CSV location (also works with --batch)")
    else:
        update_data()